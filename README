1) EvalGIM was used to generate images from the diffusion model and evaluate the generated images from both the diffusion and infinity model
- Go to {/EvalGIM/evaluation_library/generate.py} and change the dimesions of generated image required at lines 121-122
- Run the following command: python -m evaluation_library.generate --model_id CompVis/stable-diffusion-v1-4 --batch_size 4 --json_file {path to index.json} --local

2) Infinity was used to generate the images for the Infinity model
- Go to file {/notebooks/Infinity/scripts/index.sh}
- Change the pn to 0.06M, 0.25M, 1M for (256x256), (512x512), (1024, 1024) images respectively
- Download these weights and models and place them under a weights folder in the main directory:
    - https://huggingface.co/FoundationVision/Infinity/blob/main/infinity_2b_reg.pth
    - https://huggingface.co/FoundationVision/Infinity/blob/main/infinity_vae_d32reg.pth
    - https://huggingface.co/google/flan-t5-xl/tree/main -> Place this entire repository under weights/flan-t5-xl
 - Run the index.sh script to generate the images
 - Prompts can be found in: {/Infinity/scripts/prompt_image_pairs.txt}
 
 3) t2v_metrics was used to generate the VQAScore for the generated images
 - Go to {/notebooks/t2v_metrics/generate_score.py}
 - Change the img_path, index_json_path (where the index.json file is stored), and the score_output_path respectively
 - Run the file to generate the VQAScore

 4) *_diffusion/infinty_score.json store the VQAScores generated for the prompt-image pairs

 5) index.json is the file used be EvalFIM an t2v_metrics as mentioned in their respective sections (1), (3)

 6) prompt_image_pairs.txt cotains the prompt-image pairs in a text file used by Infinity (2)

 7) diffusion/infinity_{size}.zip contains the images generated from the 2 models. The 1024x1024 images for both models had to be split as they were too large